{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dddee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Rescaling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from abc import ABC, abstractmethod\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db71945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress harmless warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "141c1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistClassifierInterface(ABC):\n",
    "    \"\"\"\n",
    "    Definition of an abstract class, that has no implementation yet.\n",
    "    Defines base for derived MNIST classifiers.\n",
    "    It puts a requirement for train() and predict() to be implemented further.\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"Trains the specific model using the provided data.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Performs predictions on the test data.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72025169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFClassifier(MnistClassifierInterface):\n",
    "    \"\"\"\n",
    "    Random Forest Classifier implementation.\n",
    "    Requires flattened image input (N, 784).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        N_ESTIMATORS = 10 # forest tree count\n",
    "        N_JOBS = -1 # use all cores available\n",
    "        self.model = RandomForestClassifier(random_state=42, n_estimators=N_ESTIMATORS, n_jobs=N_JOBS)\n",
    "        print(\"RF Classifier initialized.\")\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print(\"Starting RF training...\")\n",
    "        # random Forest requires flattened input, which is handled in the MnistClassifier setup\n",
    "        self.model.fit(X_train, y_train)\n",
    "        print(\"RF training complete.\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # returns the predicted class (0-9)\n",
    "        return self.model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef3cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNClassifier(MnistClassifierInterface):\n",
    "    \"\"\"\n",
    "    Feed-Forward Neural Network (Dense layers) implementation.\n",
    "    Requires flattened and normalized input (N, 784).\n",
    "    Assembled of dense layers with neuron quantity of 2^n.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # input shape expects the flattened 784 features\n",
    "        N_CLASSES = 10 # 10 classes (digits 0-9)\n",
    "        PIXEL_TOTAL = 28 * 28 # total pixels\n",
    "        LAYER1_NEURONS = 128\n",
    "        LAYER2_NEURONS = 64\n",
    "        self.model = Sequential([\n",
    "            Dense(LAYER1_NEURONS, activation='relu', input_shape=(PIXEL_TOTAL,)),\n",
    "            Dense(LAYER2_NEURONS, activation='relu'),\n",
    "            Dense(N_CLASSES, activation='softmax')\n",
    "        ])\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy', # works with integer labels (0-9)\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(\"NN Classifier initialized.\")\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        NN requires normalized input (0-1),\n",
    "        which is handled in the MnistClassifier setup\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Starting NN training (1 epoch)...\")\n",
    "        N_EPOCHS = 1 # training iterations\n",
    "        BATCH_SIZE = 32\n",
    "        IS_VERBOSE = False # suppress NN logs\n",
    "        self.model.fit(X_train, y_train, epochs=N_EPOCHS, batch_size=BATCH_SIZE, verbose=IS_VERBOSE)\n",
    "        print(\"NN training complete.\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Returns probabilities; we need to convert to class index (0-9)\n",
    "        IS_VERBOSE = False # suppress NN logs\n",
    "        probabilities = self.model.predict(X_test, verbose=IS_VERBOSE)\n",
    "        return np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d2dbe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(MnistClassifierInterface):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network implementation for MNIST.\n",
    "    Requires 4D input (N, 28, 28, 1) and normalization (0-1).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.model = Sequential([\n",
    "            # input shape is 28x28x1\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            Flatten(),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(\"CNN Classifier initialized.\")\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print(\"Starting CNN training (1 epoch)...\")\n",
    "        # CNN requires 4D input and normalization, handled in MnistClassifier setup\n",
    "        self.model.fit(X_train, y_train, epochs=1, batch_size=32, verbose=0)\n",
    "        print(\"CNN training complete.\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # returns probabilities; we need to convert to class index (0-9)\n",
    "        probabilities = self.model.predict(X_test, verbose=0)\n",
    "        return np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "261e1e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# factory-type class\n",
    "\n",
    "class MnistClassifier:\n",
    "    \"\"\"\n",
    "    A unified interface that selects the correct concrete classifier \n",
    "    and handles data preprocessing specific to the chosen algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    ALGORITHMS = {'rf': RFClassifier, 'nn': NNClassifier, 'cnn': CNNClassifier}\n",
    "\n",
    "    def __init__(self, algorithm: str, X_data, y_data):\n",
    "        \"\"\"\n",
    "        Initializes the MnistClassifier by selecting the correct concrete model \n",
    "        and preparing the data for that model.\n",
    "        \"\"\"\n",
    "        algorithm = algorithm.lower()\n",
    "        if algorithm not in self.ALGORITHMS:\n",
    "            raise ValueError(f\"Unknown algorithm: {algorithm}. Must be one of {list(self.ALGORITHMS.keys())}\")\n",
    "\n",
    "        self.algorithm_name = algorithm\n",
    "        self.model: MnistClassifierInterface = self.ALGORITHMS[algorithm]()\n",
    "        \n",
    "        # store original data\n",
    "        self._X_train_orig, self._y_train = X_data[0], y_data[0]\n",
    "        self._X_test_orig, self._y_test = X_data[1], y_data[1]\n",
    "\n",
    "        # process data based on algorithm requirements\n",
    "        self.X_train, self.X_test = self._preprocess_data(algorithm)\n",
    "\n",
    "    def _preprocess_data(self, algorithm):\n",
    "        \"\"\"Handles necessary reshaping and normalization based on the model type.\"\"\"\n",
    "        \n",
    "        # cast to float32 for TensorFlow/NumPy operations\n",
    "        X_train, X_test = self._X_train_orig.astype('float32'), self._X_test_orig.astype('float32')\n",
    "\n",
    "        if algorithm in ['rf', 'nn']:\n",
    "            # RF and Feed-Forward NN require flattened input (N, 784)\n",
    "            print(f\"Preprocessing: Flattening data for {algorithm.upper()}...\")\n",
    "            N_train, H, W = X_train.shape\n",
    "            N_test, _, _ = X_test.shape\n",
    "            \n",
    "            # reshape using -1 to calculate the features automatically\n",
    "            X_train_processed = X_train.reshape(N_train, -1)\n",
    "            X_test_processed = X_test.reshape(N_test, -1)\n",
    "\n",
    "            # NN requires normalization for consistency\n",
    "            if algorithm == 'nn':\n",
    "                print(\"Preprocessing: Normalizing data for NN...\")\n",
    "                X_train_processed /= 255.0\n",
    "                X_test_processed /= 255.0\n",
    "            \n",
    "            return X_train_processed, X_test_processed\n",
    "\n",
    "        elif algorithm == 'cnn':\n",
    "            # CNN requires 4D input (N, 28, 28, 1) and normalization (0-1)\n",
    "            print(\"Preprocessing: Reshaping and normalizing data for CNN...\")\n",
    "            # reshape to 4D: N, H, W, Channels\n",
    "            X_train_processed = X_train[..., np.newaxis]\n",
    "            X_test_processed = X_test[..., np.newaxis]\n",
    "            \n",
    "            # normalize pixel values\n",
    "            X_train_processed /= 255.0\n",
    "            X_test_processed /= 255.0\n",
    "            \n",
    "            return X_train_processed, X_test_processed\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Delegates the training call to the underlying model.\"\"\"\n",
    "        self.model.train(self.X_train, self._y_train)\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Delegates the prediction call and returns the result, \n",
    "        maintaining a consistent output structure regardless of model.\n",
    "        \"\"\"\n",
    "        print(f\"\\nMaking predictions using {self.algorithm_name.upper()}...\")\n",
    "        return self.model.predict(self.X_test)\n",
    "    \n",
    "    def evaluate(self, y_pred):\n",
    "        \"\"\"Calculates and prints the accuracy of the predictions.\"\"\"\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score(self._y_test, y_pred)\n",
    "        print(f\"Accuracy for {self.algorithm_name.upper()}: {accuracy:.4f}\")\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aa9f390-fef5-40fa-b8f0-c31b2938f3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading and preparation...\n",
      "Loaded 5000 training samples and 5000 test samples.\n",
      "\n",
      "==========================================\n",
      "STARTING MODEL: RF\n",
      "==========================================\n",
      "RF Classifier initialized.\n",
      "Preprocessing: Flattening data for RF...\n",
      "Starting RF training...\n",
      "RF training complete.\n",
      "\n",
      "Making predictions using RF...\n",
      "Accuracy for RF: 0.8498\n",
      "First 5 predictions: [7, 2, 1, 0, 4]\n",
      "\n",
      "==========================================\n",
      "STARTING MODEL: NN\n",
      "==========================================\n",
      "NN Classifier initialized.\n",
      "Preprocessing: Flattening data for NN...\n",
      "Preprocessing: Normalizing data for NN...\n",
      "Starting NN training (1 epoch)...\n",
      "NN training complete.\n",
      "\n",
      "Making predictions using NN...\n",
      "Accuracy for NN: 0.8550\n",
      "First 5 predictions: [7, 2, 1, 0, 4]\n",
      "\n",
      "==========================================\n",
      "STARTING MODEL: CNN\n",
      "==========================================\n",
      "CNN Classifier initialized.\n",
      "Preprocessing: Reshaping and normalizing data for CNN...\n",
      "Starting CNN training (1 epoch)...\n",
      "CNN training complete.\n",
      "\n",
      "Making predictions using CNN...\n",
      "Accuracy for CNN: 0.9094\n",
      "First 5 predictions: [7, 2, 1, 0, 4]\n",
      "\n",
      "--- Summary of Results ---\n",
      "| RF  Accuracy: 0.8498\n",
      "| NN  Accuracy: 0.8550\n",
      "| CNN Accuracy: 0.9094\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "\n",
    "def main():\n",
    "    print(\"Data loading and preparation...\")\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # use only a small subset of data for fast demonstration\n",
    "    subset_size = 5000\n",
    "    X_train, y_train = X_train[:subset_size], y_train[:subset_size]\n",
    "    X_test, y_test = X_test[:subset_size], y_test[:subset_size]\n",
    "    print(f\"Loaded {len(X_train)} training samples and {len(X_test)} test samples.\")\n",
    "    data_X = (X_train, X_test)\n",
    "    data_y = (y_train, y_test)\n",
    "\n",
    "    # List of algorithms to test\n",
    "    algorithms_to_test = ['rf', 'nn', 'cnn']\n",
    "    results = {}\n",
    "    for algo in algorithms_to_test:\n",
    "        print(f\"\\n==========================================\")\n",
    "        print(f\"STARTING MODEL: {algo.upper()}\")\n",
    "        print(f\"==========================================\")\n",
    "        \n",
    "        try:\n",
    "            # classifier instance\n",
    "            classifier = MnistClassifier(algo, data_X, data_y)\n",
    "            \n",
    "            # model training\n",
    "            classifier.train()\n",
    "            \n",
    "            # test prediction\n",
    "            predictions = classifier.predict()\n",
    "            \n",
    "            # performance estimation\n",
    "            accuracy = classifier.evaluate(predictions)\n",
    "            results[algo] = accuracy\n",
    "            \n",
    "            # head elements among predicted classes\n",
    "            print(f\"First 5 predictions: {predictions[:5].tolist()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred with {algo.upper()}: {e}\")\n",
    "            results[algo] = \"Failed\"\n",
    "\n",
    "    print(\"\\n--- Summary of Results ---\")\n",
    "    for algo, acc in results.items():\n",
    "        print(f\"| {algo.upper():<3} Accuracy: {acc if isinstance(acc, str) else f'{acc:.4f}'}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
